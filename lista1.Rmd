---
title: "Untitled"
author: "LoRiVaL"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F)
```

## Lista de Exercícios I 

1. A reta de regressão obtida pelo método dos mínimos quadrados (MMQ) possui propriedades. Algumas delas necessitam ser demonstradas:
<br>

&emsp;&emsp; (a) que 
$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1} x_i^2 - n \bar x^2;$$

Abrindo o binômio temos,

$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2 - 2x_i\bar x + \bar x^2)$$
Distribuindo o somatório,

$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2) - \sum^n_{i=1}(2x_i\bar x) + \sum^n_{i=1}(\bar x^2)$$

$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2) - 2 \bar x\sum^n_{i=1}(x_i) + n\bar x^2$$
$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2) - 2 \bar x n \bar x + n\bar x^2$$
$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2) - 2 n\bar x^2 + n\bar x^2$$

$$\sum^n_{i=1}(x_i - \bar x)^2 = \sum^n_{i=1}(x_i^2) - n\bar x^2$$
<br><br>

&emsp;&emsp;(b) a soma dos valores observados é igual à soma dos valores estimados, isto é,

$$\sum^n_{i=1} y_i = \sum^n_{i=1} \hat y_i$$
Sabemos que $\hat y_i = \hat \beta_0 + \hat \beta_1 x_i$ e que  $\hat \beta_0 = \bar y - \hat \beta_1 \bar x$, assim

$$\sum_{i=1}^n \hat y_i = \sum^n_{i=1} \left( \hat \beta_0 + \hat \beta_1 x_i \right) =
\sum_{i=1}^n \left(\bar y - \hat \beta_1 \bar x + \hat \beta_1 x_i\right)$$

$$\sum_{i=1}^n \hat y_i = \sum_{i=1}^n (\bar y) - \sum_{i=1}^n(\hat \beta_1 \bar x) + \sum_{i=1}^n(\hat \beta_1 x_i)$$
$$\sum_{i=1}^n \hat y_i = n\bar y - n\hat \beta_1 \bar x + \hat \beta_1\sum_{i=1}^n( x_i)$$
$$\sum_{i=1}^n \hat y_i = n\bar y - n\hat \beta_1 \bar x + \hat \beta_1 n \bar x$$
$$\sum_{i=1}^n \hat y_i = n\bar y$$
$$\sum^n_{i=1} y_i = n \bar y$$
Portanto,

$$\sum^n_{i=1} y_i = \sum^n_{i=1} \hat y_i =  n \bar y$$
<br><br>

&emsp;&emsp;(c) A soma dos resíduos é igual a zero, isto é,

$$\sum^n_{i=1} e_i = 0$$

Sabemos que $e_i = y_i -\hat y_i$, portanto

$$\sum^n_{i=1} e_i = \sum^n_{i=1} (y_i -\hat y_i) = \sum^n_{i=1}y_i -\sum^n_{i=1}\hat y_i $$
$$\sum^n_{i=1} e_i = n \bar y - n \bar y = 0$$
$$\sum^n_{i=1} e_i = 0$$
&emsp;&emsp; (d) a soma do produto dos valores estimados e resíduos é igual a zero, isto é,

$$\sum^n_{i=1} \hat y_i e_i = 0$$
<br><br><br>

2. Faça o que se pede:


&emsp;&emsp;(a) Simule n = 30 valores para o Modelo de Regressão Linear Simples (MRLS) (semente 350) dado por: $Y = −2 + 0.5x + \epsilon$ tal que 
  
&emsp;&emsp;&emsp;&emsp;$X$∼$N(0, 1)$ e $\epsilon$ ∼ $N(0, \sigma^2 = 9)$;
  
```{r}
set.seed(350)
n    <- 30
x    <- rnorm(n)
erro <- rnorm(n, 0, 3)
y    <- -2 + 0.5*x + erro
```
<br><br>
Os dados simulados por $Y = −2 + 0.5x + \epsilon$, dado que $X$∼$N(0, 1)$ e $\epsilon$ ∼ $N(0, \sigma^2 = 9)$ são os seguintes

```{r}
print(y)
```
<br><br>
&emsp;&emsp;(b) Apresente o diagrama de dispersão dos dados;

```{r}
plot(x, y,
     xlab = 'X',
     ylab = 'Y',
     main = 'Gráfico de dispersão dos dados simulados'
     )

```
Os dados se concentram em torno do -2, devido terem sido gerados para isso, pois $Y = −2 + 0.5x + \epsilon$, e $x$ possui média zero e distribuição normal, no entanto mesmo a função $Y$ sendo de uma reta, os dados não distribuem tão bem na forma de uma reta, possivelmente, devido a variância dos resíduos ser relativamente alta $\sigma^2 = 9$.

  
  
&emsp;&emsp;(c) Estime os parâmetros do modelo via MMQ e pela forma matricial, isto é,
  $\hat \beta = (X′X)^{-1} X′y$;
  
Via MMQ, temos que $\hat \beta_0 = \bar y - \hat \beta_1 \bar x$ &emsp; e &emsp; $\hat \beta_1 = \frac{\sum^n_{i=1}(x_i - \bar x)(y_i - \bar y)} {\sum^n_{i=1}(x_i - \bar x)^2}$
<br>
Assim, para calcular $\bar \beta_1$, temos $\bar x = 0.04636292$ e $\bar y = -2.176858 $, assim, conseguimos um $\beta_1 = 0.26286$ e usando esse para calcular $\beta_0$ temos que esse vale $-2.189045$. <br> <br>

Assim teríamos que a reta de regressão é dada por $-2.189045 + 0.26286x$, plotando-a nos dados teríamos o seguinte 

```{r}
beta_1 = sum((x - mean(x)) * (y - mean(y))) / sum((x - mean(x))^2)

beta_0 = mean(y) - beta_1*mean(x)

plot(x, y,
     xlab = 'X',
     ylab = 'Y',
     main = 'Gráfico de dispersão dos dados simulados'
     )
curve(beta_0 + beta_1*x, add =T, col = 'red')

```

<br>

  
Pela forma matricial precisamos calular $\hat \beta = (X′X)^{-1} X′Y$, para isso, primeiramente precisamos definir as matrizes $X$ e $Y$, temos que $X$ é
```{r}
matriz_x = matrix(c(rep(1,n),x), ncol =2)
matriz_x
```
E que $Y$ é,

```{r}
matriz_y = matrix(y)
matriz_y
```

Precisamos também encontrar a transposta de $X$, a matriz $X'$, sendo essa

```{r}
t(matriz_x)
```

calculando $X'X$, temos

```{r}
t(matriz_x) %*% matriz_x
```

Agora invertendo essa matriz, temos

```{r}
solve(t(matriz_x) %*% matriz_x)
```

Calculando $X' Y$,


```{r}
t(matriz_x) %*% matriz_y
```

Agora calculando $\hat \beta$ de fato,

```{r}
solve(t(matriz_x) %*% matriz_x) %*% t(matriz_x) %*% matriz_y
```
Assim temos que $\beta_0 = -2.189045$ e $\beta_1 = 0.262860$, e a reta de regressão  $-2.189045 + 0.262860x$, o mesmo valor calculado de forma analítica. <br>
  
plotando essa função teríamos a seguinte reta,
```{r}
betas <- solve(t(matriz_x) %*% matriz_x) %*% t(matriz_x) %*% matriz_y

plot(x, y,
     xlab = 'X',
     ylab = 'Y',
     main = 'Gráfico de dispersão dos dados simulados'
     )
curve(betas[1] + betas[2]*x, add =T, col = 'red')
```
<br><br>

  (d) Apresente o histograma dos erros e teste sua normalidade via Shapiro-Wilk.
 
```{r}
hist(erro, 
     xlab = 'Erro',
     ylab = 'Frequência',
     main = 'Histograma dos erros')

```
Podemos vizualizar que os valores mais frequêntes se encontra de -2 a 2.
<br>
Agora para testar a normalidade dos resíduos será usado o teste de Shapiro-Wilk que possui as seguintes hipóteses

$$
    \begin{cases}
H_{0}: \textrm{Os dados seguem uma distribuição normal.}\\
H_{1}: \textrm{Os dados não se distribuem como uma normal.}
    \end{cases}
$$

```{r}
shapiro.test(erro)
```
Verificando a normalidade dos resíduos, temos que utilizando 95% de confiança, não rejeitamos $H_0$, ou seja, temos indícios de que os erros seguem normalidade.

<br><br>

3) Com o objetivo de se estudar a relação entre Tempo de uma reação química (resposta) e Temperatura, um certo experimento foi realizado. A Tabela 1 a seguir contém os valores das temperaturas, em $°C$, e os tempos obtidos, em segundos

```{r}
L1 <- c(11.3, 11.8, 11.5, 12.1, 11.7)
L2 <- c(11.8, 11.5, 11.4, 11.7, 11.2)
L3 <- c(10.9, 11.2, 10.8, 10.6, 10.3)
L4 <- c(10.4, 9.8 , 9.5 , 9.9 , 9.2 )
L5 <- c(9.6 , 9.0 , 8.7 , 8.3 , 9.1 )
L6 <- c(9.1 , 9.3 , 8.5 , 8.6 , 8.3 )
L7 <- c(8.4 , 8.1 , 8.1 , 7.7 , 7.9 )

temperatura <- c(rep(20, 5), rep(30, 5), rep(40, 5),
                 rep(50, 5), rep(60, 5), rep(70, 5),
                 rep(80, 5))

tempo       <- c(L1, L2, L3, L4, L5, L6, L7)


dados       <- data.frame(Temperatura <- temperatura,
                          Tempo       <- tempo)

colnames(dados) <- c('Temperatura', 'Tempo')

print(dados)

```
<br><br>
&emsp;&emsp;a) Apresente o diagrama de dispersão dos dados;

```{r}
plot(dados$Temperatura, dados$Tempo,
     xlab = 'Temperatura',
     ylab = 'Tempo',
     main = 'Gráfico de dispersão do tempo pela temperatura')
```
<br>
O gráfico de dispersão é no eixo tempo contínuo e no eixo temperatura discreto, os pontos formam, aparentemente, uma reta.

<br><br>
&emsp;&emsp;b) Estime a média, desvio-padrão, variância e coeficiente de variação para a resposta (Tempo de reação), considerando-a como normalmente distribuiída (Sugestão: Utilize a função fitdistr da livraria MASS do R)

```{r}
library(MASS)

est_L1 <- fitdistr(L1, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L2 <- fitdistr(L2, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L3 <- fitdistr(L3, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L4 <- fitdistr(L4, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L5 <- fitdistr(L5, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L6 <- fitdistr(L6, dnorm, start = list(mean= 10, sd= 2))$estimate
est_L7 <- fitdistr(L7, dnorm, start = list(mean= 10, sd= 2))$estimate

estimativas <- data.frame(rbind(est_L1, est_L2, est_L3,
                     est_L4, est_L5, est_L6, est_L7))

estimativas$var <- estimativas$sd**2
estimativas$cv  <- estimativas$sd / estimativas$mean

row.names(estimativas) <- c(seq(20, 80, 10))

print(estimativas)

```

Estimando as estatísticas via o *fitdistr*, temos um coeficiente de variação baixo para todas temperaturas, ou seja, a média pode ser usada para representar os dados, e temos o comportamento esperado de acordo com o gráfico para as médias, conforme a temperatura diminui a média do tempo aumenta.


<br><br>

&emsp;&emsp;c) Calcule a média, desvio-padrão, variância e coeficiente de variação para a resposta em cada nível de temperatura e responda se há algum indício de heterocedasticidade. Justifique;

```{r}
tempos      <- data.frame(T20 = L1, T30 = L2, T40 = L3, T50 = L4,
                          T60 = L5, T70 = L6, T80 = L7 )


estimativas <- data.frame(
                          apply(tempos, 2, FUN = function(x)
                                  {media  <- mean(x)
                                   desvio <- sd(x)
                                   varia  <- var(x)
                                   cv     <- sd(x)/mean(x)
                                   return(c(media, desvio, varia, cv))
                                   }))

row.names(estimativas) <- c('mean', 'sd', 'var', 'cv')
estimativas            <- data.frame(t(estimativas))

estimativas

```
Sem realizar testes, eu diria que, aparentemente, não há heterocedasticidade, pois, a variância tem um aumento na temperatura 50, 60 e 70, mas depois disso ela abaixa novamente, não explodindo conform a variável x aumenta, como é comum no caso de heterocedasticidade. No entanto, para verificar se a variação da variância pode ser considerada alta o suficiente e por conseguinte não existir homocedasticidade, é necessário fazer os testes específicos para isso.

<br><br>

&emsp;&emsp;d) Estime os parâmetros do MRLS da Temperatura versus Tempo via comando *lm* do R;

```{r}

modelo1 <- lm(Tempo ~ Temperatura, data = dados)
modelo1
```
Assim temos o seguinte modelo, *Tempo* = 13.18357 - 0.06521 $\cdot$ *Temperatura*.

E agora que temos um modelo, podemos verificar a heterocedasticidade do exercício anterior. Para isso, o teste de Goldfeld-Quandt será usado, o qual possui as seguintes hipóteses,

$$
    \begin{cases}
H_{0}: \textrm{A homocedasticidade está presente.}\\
H_{1}: \textrm{A homocedasticidade não está presente.}
    \end{cases}
$$
```{r}

library(lmtest)

gqtest(modelo1)

```
Assim, considerando uma confiança de 95%, não rejeitamos $H_0$, ou seja, a homocedasticidade está presente.

<br><br>
&emsp;&emsp;e) Teste a significância dos parâmetros em nível de 5%;

Para testar a significância de $\beta_1$, temos dois passos a serem seguidos,

- Usar um teste t para as seguintes hipóteses
$$
    \begin{cases}
H_{0}: {\beta_1 = 0}\\
H_{1}: {\beta_1 \not = 0}
    \end{cases}
$$
- Usar o teste F ao ajustamento global do modelo.
<br>
Realizando o teste t,

$$t_c = \frac{\hat \beta_1 - \beta_1}{\sqrt{\frac{QME}{Sxx}}}$$
$t_c$ &nbsp;~&nbsp; $t_{ n-2, \alpha}$ <br>

$$S_{xx} = \sum^n_{i=1} (x_i - \bar x)^2 = 14000$$
$$QME = \frac{SQE}{(n-2)} =  \frac{\sum^n_{i=1}(y_i - \hat y_i)^2}{(n-2)}$$
$$QME = \frac{5.381071}{35}= 0.1537449$$
$$t_c = \frac{\hat \beta_1 - \beta_1}{\sqrt{\frac{QME}{Sxx}}}$$
$$t_c = \frac{-0.06521429 - 0}{\sqrt{\frac{0.1537449}{14000}}} = -19.67915$$
Temos que a área de não rejeição dada por $t_{33, 0.025} < t_c < t_{33, 0.975}$, pegando os valores de $t$ tabelados, temos que essa área é dada por $-2.034515 < t_c < 2.034515$. Portanto $t_c < -2.034515$, e então com 95% de confiança rejeitamos $H_0$, ou seja, $\beta_1$ é diferente de zero.
```{r}
residuo <- Tempo - modelo1$fitted.values
tc <- (modelo1$coefficients[2] - 0)/((sum(residuo^2))/length(residuo)/ sum((Temperatura - mean(Temperatura))^2))^0.5

#qt(0.975, 33)
```

&emsp;&emsp;f) Teste a normalidade nos resíduos;

Para testar a normalidade dos resíduos será usado o teste de Shapiro-Wilk, quue possui as seguintes hipóteses,

$$
    \begin{cases}
H_{0}: \textrm{Os dados seguem uma distribuição normal.}\\
H_{1}: \textrm{Os dados não se distribuem como uma normal.}
    \end{cases}
$$

```{r}
shapiro.test(modelo1$residuals)
```
Assim, com 95% de confiança não rejeitamos $H_0$, ou seja, os resíduos do modelo seguem a distribuição normal, assim esses pressuposto está sendo seguido.


&emsp;&emsp;g) Trace a reta estimada sobre os pontos observados;

```{r}
plot(dados$Temperatura, dados$Tempo,
     xlab = 'Temperatura',
     ylab = 'Tempo',
     main = 'Gráfico de dispersão do tempo pela temperatura')
curve(modelo1$coefficients[1] + modelo1$coefficients[2]*x, add = T, col = 'red', lty = 1, lwd = 2)

```
<br>
Assim como visualizado no gráfico de dispersão inicial, os pontos formam uma espécie de reta, e o modelo consegue ajustar uma reta de regressão que passe pelo meio de todos pontos nos grupos de temperatura. <br><br>

&emsp;&emsp;h) Construa intervalos de 95% de confiança para os parâmetros estimados;

```{r}
confint(modelo1)
```
Temos que com 95% de confiança, $\beta_0$ está entre 12.80965603 e 13.55748683, enquanto $\beta_1$ está entre -0.07215772 e  -0.05827085.
<br><br>

4. As tabelas 2 e 3 a seguir, fazem parte da saída de uma análise de regressão realizada em um determinado programa estatístico.
<br>

<center>
| Parameter | Estimate | Srd. Error | t value | p     |
|-----------|----------|------------|---------|-------|
| Intercept | 83.0740  | 6.5930     | 12.60   | 0.000 |
| x         | -1.1848  | 0.1258     | -9.42   | 0.000 |
<br>

| FV        | Df | Sum Sq | Mean Sq | F value | p     |
|-----------|----|--------|---------|---------|-------|
| x         | 1  | 1021.1 | 1021.1  | 88.68   | 0.000 |
| Residuals | 7  | 80.6   | 11.5    |         |       |
| Total     | 8  | 1101.6 |         |         |       |
</center>

&emsp;&emsp; (a) Escreva a equação da reta ajustada;

&emsp;&emsp; (b) Encontre um intervalo de confiança de 95%, para os coeficientes da reta ajusta;

&emsp;&emsp; (c) Verifique se o modelo contribui para explicar a variável resposta. Está adequado? Justifique;

&emsp;&emsp; (d) Encontre a estimativa da variância residual;

<br><br>

5. Um experimento foi conduzido para avaliar, em coelhos a disponibilidade relativa (DR) do Fósforo existente nos Fosfatos da rocha Araxá e de Patos de Minas em relação ao Fósforo existente no Fostato Bicálcico. Os animais foram alimentados com rações contendo níveis crescentes de cada Fosfato  e foram anotados os consumos de ração, o que permitiu calcular o consumo de Fósforo em cada unidade experimental. A variável resposta observada foi a resistência do fêmur à quebra, mensurada com dinamômetro (Tabela 4).

A disponibilidade relativa é estimada pela razão entre o coeficiente linear de regressão (angular no caso da reta) obtido para o Fosfato de interesse e para o Fosfato Bicálcico, isto é:

$$DR^* = \beta_1^* / \beta_1^{Bicalcico}$$
<br>

\begin{array}{cc|cc|cc}
\hline
\textrm{Araxa}  &&\textrm{Patos}&&\textrm{Bicalcico}&\\
\hline
\textrm{Y}      &\textrm{X}&\textrm{Y}&\textrm{X}&\textrm{Y}&\textrm{X}\\
\hline
                21.28&0.184&23.50&0.195&25&0.18\\
                31.60&0.350&34.59&0.350&39&0.36\\
                32.42&0.516&31.18&0.505&43&0.50\\
                41.74&0.683&43.27&0.661&60&0.65\\
                420.6&0.849&40.36&0.816&63&0.78\\
                53.38&1.015&50.45&0.972&71&0.94\\
\hline
\end{array}

&emsp;&emsp; (a) Ajuste os modelos individuais;

```{r}
araxa <- data.frame(Y = c(21.28,31.60,32.42,41.74,42.06,53.38),
                    X = c(0.184,0.350,0.516,0.683,0.849,1.015))
patos <- data.frame(Y = c(23.50,34.59,31.18,43.27,40.36,50.45),
                    X = c(0.195,0.350,0.505,0.661,0.816,0.972))
bical <- data.frame(Y = c(25,39,43,60,63,71),
                    X = c(0.18,0.36,0.50,0.65,0.78,0.94))

modelo_araxa <- lm(Y ~ X, data = araxa)
modelo_patos <- lm(Y ~ X, data = patos)
modelo_bical <- lm(Y ~ X, data = bical)
```
<br>

**Modelo Araxá**: $Y = 16.35 + 34.58 \cdot X$

O ajuste aos dados,

```{r}
plot(x = araxa$X, y = araxa$Y,
     xlab = 'Fósforo',
     ylab = 'Resistência do Fêmur à quebra',
     main = 'Gráfico de dispersão e ajuste do modelo araxá ')
curve(modelo_araxa$coefficients[1] + modelo_araxa$coefficients[2]*x ,  col = 'red', lwd = 2, add=T)


```

**Modelo Patos**: $Y = 19.62 + 30.19 \cdot X$

O ajuste aos dados,

```{r}
plot(x = patos$X, y = patos$Y,
     xlab = 'Fósforo',
     ylab = 'Resistência do Fêmur à quebra',
     main = 'Gráfico de dispersão e ajuste do modelo Patos ')
curve(modelo_patos$coefficients[1] + modelo_patos$coefficients[2]*x ,  col = 'red', lwd = 2, add=T)


```

**Modelo Bicálcico**: $Y = 15.27 + 61.40 \cdot X$

O ajuste aos dados,

```{r}
plot(x = bical$X, y = bical$Y,
     xlab = 'Fósforo',
     ylab = 'Resistência do Fêmur à quebra',
     main = 'Gráfico de dispersão e ajuste do modelo Bicálcico ')
curve(modelo_bical$coefficients[1] + modelo_bical$coefficients[2]*x ,  col = 'red', lwd = 2, add=T)


```
<br>

Assim os 3 modelos conseguiram ajustar, aparentemente, bem os dados, visto que esses se distribuim em forma de reta.

<br>

```{r}
summary(modelo_araxa)
summary(modelo_patos)
summary(modelo_bical)
```

<br>

Para todos modelos, temos que tanto o intercepto quanto o X é significativo usando 99% de confiança, com um $R^2$ maior que 0.8 chegando a 0.96.

<br><br>

&emsp;&emsp; (b) Calcule a disponibilidade relativa do Fósgoro nos dois Fosfatos de rocha e decida pelo melhor;

Temos que

$$DR_{araxa} =  \beta_1^{araxa} / \beta_1^{Bicalcico} = \frac{34.57651}{61.39689} = 0.5631639$$
$$DR_{patos} =  \beta_1^{patos} / \beta_1^{Bicalcico} = \frac{30.18677}{61.39689} = 0.4916661$$
Assim, a rocha de Araxá tem um $DR$ maior que a de Patos de Minas, e por consequência possui mais Fósforo.


```{r}
DR_araxa <- modelo_araxa$coefficients[2] / modelo_bical$coefficients[2]
 # Quanto mais melhor
DR_patos <- modelo_patos$coefficients[2] / modelo_bical$coefficients[2]
```



&emsp;&emsp; (c) Trace as retas ajustadas aos dados simultaneamente.

```{r}
dados <- rbind(araxa, patos, bical)

plot(x = dados$X, y = dados$Y,
     xlab = 'Fósforo',
     ylab = 'Resistência do Fêmur à quebra',
     main = 'Gráfico de dispersão e ajuste do modelos')
curve(modelo_araxa$coefficients[1] + modelo_araxa$coefficients[2]*x ,  col = 'red', lwd = 2, add=T, lty=2)
curve(modelo_patos$coefficients[1] + modelo_patos$coefficients[2]*x ,  col = 'blue', lwd = 2, add=T, lty=2)
curve(modelo_bical$coefficients[1] + modelo_bical$coefficients[2]*x ,  col = 'green3', lwd = 2, add=T, lty=2)

text(x=0.8, y=70, "Bicálcico",col = 'green3')
text(x=1, y=46, "Patos",col = 'blue')
text(x=0.9, y=53, "Araxá",col = 'red')
```


<br><br>

6. Com base nos dados do Instituto Nacional de Estatística de Portugal (INE), o arquivo **cereais** contém a evolução da superfície agrícola (y) utilizada anualmente na produção de cereais para grão (y: **area**, em $km^2$) em Portugal, no éríodo de 1968 a 2011 (x: **ano**). Faça o que se pede:
```{r}
cereais <- read.table(file = 'dados/cereais.txt',header = T)
cereais
```


&emsp;&emsp; (a) Construa uma nuvem de pontos de superfície agrícola vs. ano e comente;

```{r}

plot(x = cereais$ano, y = cereais$area,
     xlab = 'Ano',
     ylab = 'Superfície agrícola',
     main = 'Gráfico de dispersão do ano pela área agrícola')
```
<br>
No gráfico acima, podemos verificar que os pontos de superfície e ano formam uma reta.
<br><br>

&emsp;&emsp; (b) A partir do gráfico obtido do item anterior, sugira um valor para o coeficiente de correlação entre superfície agrícola e ano. Depois, utilize os comandos do R para calcular esse mesmo coeficiente de correlação. Comente o seu significado;
<br>
Apenas pelo gráfico de dispersão, a correlação parece ser bem alta pelos dados formarem uma reta muito bem definida e com os pontos próximo, sugerindo seria um valor de $\rho=-0.9$.

<br>

Para calcular a correlação será usado o coeficiente de correlação de Pearson, visto que esse é usado para dados que tem relação linear, o coeficiente possui a seguinte fórmula,

$$\rho = \frac{cov(X,Y)}{\sqrt{var(X) \cdot var(Y)}}$$

```{r, echo = T}
cor(cereais$ano, cereais$area)
```
<br>
O $\rho = -0.9826927$, representa uma correlação inversa quase perfeita, como era observado no gráfico que forma uma reta, demonstrando que, possivelmente, o ano tem grande influência na superfície agrícola.
<br><br>

&emsp;&emsp; (c) Ajuste uma reta de regressão de superfície agrícola utilizada sobre anos. Discuta o significado dos parâmetros da reta ajustada, no contexto do problema sob estudo;

<br>

O modelo linear possui a seguinte fórmula $Y = 523001.7 -258.8X$.

```{r}
modelo1 <- lm(area ~ ano, data = cereais)

plot(x = cereais$ano, y = cereais$area,
     xlab = 'Ano',
     ylab = 'Superfície agrícola',
     main = 'Gráfico de dispersão do ano pela área agrícola')
curve(modelo1$coefficients[1] + modelo1$coefficients[2]*x, add=T,
      lwd = 2, col = 'red')
summary(modelo1)
```
<br>
Ambos parâmetros são significativos a 99.99%, temos que o Intercepto = 523001.7, ele é bem alto devido o ano estar na casa de $10^3$ diminuindo bastante esse valor, quanto ao ano = -258.8, ele é negativo assim diminuindo o valor do intercepto conforme o ano aumenta.
<br><br>

&emsp;&emsp; (d) Comente a qualidade da reta obtida, calculando o respectivo coeficiente de determinação e interpretando o valor obtido;
<br>
Temos que o coeficiente de determinação $(R^2)$ pode ser usado para testar a qualidade do ajuste, sendo calculado por

$$R^2 = \frac{SQReg}{SQT} = 
\frac{\sum^n_{i=1}(\hat Y_i - \bar Y)^2}{\sum^n_{i=1} (Y_i - \bar Y)^2}$$
<br>
```{r}
R2 <- sum((modelo1$fitted.values - mean(cereais$area))^2)/sum((cereais$area - mean(cereais$area))^2)
R2
```
$$R^2 = \frac{97924480}{101404176} =  0.965684$$

No nosso modelo, temos que $R^2 =  0.9656849$, agora calculando o coeficiente de determinação ajustado, usando
<br>
$$\bar R^2 = R^2 - \frac{1}{n-2}(1 - R^2)$$
$$\bar R^2 = 0.9656849^2 = \frac{1}{35-2}(1 - 0.9656849) = 0.9642551$$
```{r}
R2 - (1)/(nrow(cereais)-2) * (1 - R2)
```
<br>
Temos que $\bar R^2 = 0.9642551$, lembrando que $0 < R^2 < 1$ e quanto mais perto de 1 o $R$, melhor o ajuste do modelo, assim de acordo apenas com o coeficiente de determinação ajustado o modelo está explicando quase perfeitamente os dados.

<br><br>
&emsp;&emsp; (e) Trace a reta de regressão ajustada em cima da nuvem de pontos e comente;

```{r}
plot(x = cereais$ano, y = cereais$area,
     xlab = 'Ano',
     ylab = 'Superfície agrícola',
     main = 'Gráfico de dispersão do ano pela área agrícola')
curve(modelo1$coefficients[1] + modelo1$coefficients[2]*x, add=T,
      lwd = 2, col = 'red')
```
<br>

A reta se ajusta bem aos dados, visto esses terem uma alta relação linear. <br><br>

&emsp;&emsp; (f) Calcule a Soma de Quadrados Total (SQT), a partir do cálculo da variância amostral de y;
<br>

<br><br>
&emsp;&emsp; (g) Calcule o valor da Soma de Quadrados de Regressão (SQReg);
<br>

$$SQReg = \sum^n_{i=1}(\hat Y_i - \bar Y)^2 = 97924480 $$
```{r}
sum((modelo1$fitted.values - mean(cereais$area))^2)
```

<br><br>
&emsp;&emsp; (h) Calcule a Soma de Quadrados dos Resíduos (SQE), diretamente a partir dos resíduos, e verifique numericamente a relação fundamental da Regressão Linear: $SQT = SQReg + SQE$;
<br>
De exercícios anteriores temos que $SQReg = 97924480$ e $SQT = 101404176$.
<br>

$$SQT = SQReg + SQE$$
$$101404176 = 97924480 + SQE$$
$$101404176 - 97924480 = SQE$$
$$SQE = 3479696$$
<br>
Calculando diretamente pelos resíduos,

```{r}
sum(modelo1$residuals^2)
```
<br>
Tem a diferença de 1 unidade que é devido a aproximação. <br><br>

&emsp;&emsp; (i) Altere as unidades de medida da variável área, de $km^2$ para hectares(*area* $\rightarrow$ *area* $\cdot$ 100). Ajuste novamente a regressão, após efetuar essta alteração. O que aconteceu aos parâmetros estimados e ao coeficiente de determinação $R^2$? Comente;

&emsp;&emsp; (j) De novo a partir dos dados originais, transforme a variável ano num contador dos anos do estudo (*ano* $\rightarrow$ *ano* - 1985). Ajuste novamente a regressão, após efetuar esta alteração. O que aconteceu aos parâmetros estimados e ao coeficiente de determinação $R^2$? Comente.

<br><br>

7. Hsuie, Ma e Tsai (1995) estudam o efeito da **razão** molar do ácido sebácico (o regressor) na **viscosidade** intrínseca dos copoliesteres (a resposta).

&emsp;&emsp; (a) Realize uma Análise de RLS completa e apropriada;

&emsp;&emsp; (b) Apresente um gráfico simultâneo com os dados, o ajuste, o IC e o IP;

&emsp;&emsp; (c) Apresente um intervalo de predição para uma viscosidade de 0.95.

<br>

\begin{array}{c|cccccccc}
\hline
\textrm{Razão}            &1&0.9&0.8&0.7&0.6&0.5&0.4&0.3 \\
\hline
\textrm{Viscosidade}      &0.45&0.20&0.34&0.58&0.70&0.57&0.55&0.75\\
\hline
\end{array}

<br><br>


8. Com interesse de investigar a relação linear existente entre $X$ (nível de dose (%) nutricional na ração) e $Y$ (resposta à taxa de crescimento), um experimento foi realizado considerando um Delineamento Inteiramente Casualizada (DIC) em um grupo de animais. Realize uma análise completa para os dados e conclua.

\begin{array}{c|ccccccc}
\hline
\textrm{X}            &1&1&1&1&1&2&2&2&2&2&3&3&3&3&3&4&4&4&4&4&\\
\hline
\textrm{Y}      &2&2&1&1&0.1&1&0.1&0.1&1&1&12&10&14&17&11&7&9&15&8&10&\\
\hline
\end{array}
